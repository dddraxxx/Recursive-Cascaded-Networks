{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "from adet.utils.visualize_niigz import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pt_mask', 'landmark_dists', 'jaccs', 'dices', 'jacobian_det', 'warped_moving', 'real_flow', 'warped_seg_moving', 'warped_moving_0', 'warped_seg_moving_0', 'real_flow_0', 'warped_moving_1', 'warped_seg_moving_1', 'real_flow_1', 'warped_moving_2', 'warped_seg_moving_2', 'real_flow_2', 'warped_moving_3', 'warped_seg_moving_3', 'real_flow_3', 'id1', 'id2', 'seg1', 'seg2', 'img1', 'img2'])\n"
     ]
    }
   ],
   "source": [
    "# fname = '/home/hynx/regis/Recursive-Cascaded-Networks/evaluate/Jul15-1755-model-2500.pkl'\n",
    "# fname = '/home/hynx/regis/Recursive-Cascaded-Networks/evaluate/Jul20-1506-model-1500.pkl'\n",
    "# fname = '/home/hynx/regis/Recursive-Cascaded-Networks/evaluate/Jul20-1619-model-3500.pkl'\n",
    "# fname = '/home/hynx/regis/Recursive-Cascaded-Networks/evaluate/Jul26-1518-model-4500.pkl'\n",
    "# fname = '/home/hynx/regis/Recursive-Cascaded-Networks/evaluate/Aug08-1440-model-5560.pkl'\n",
    "# fname = '/home/hynx/regis/Recursive-Cascaded-Networks/evaluate/Aug08-1815-model-5700-lits.pkl'\n",
    "fname = '/home/hynx/regis/Recursive-Cascaded-Networks/evaluate/VTN-3-liver-model-99500.pkl'\n",
    "dct = pkl.load(open(fname, 'rb'))\n",
    "print(dct.keys())\n",
    "# print(dct['dices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 128)\n",
      "Visualizing img with shape and type: torch.Size([43, 1, 128, 128]) torch.float32\n",
      "img1\n",
      "(128, 128, 128)\n",
      "Visualizing img with shape and type: torch.Size([43, 1, 128, 128]) torch.float32\n",
      "img2\n",
      "(128, 128, 128)\n",
      "Visualizing img with shape and type: torch.Size([43, 1, 128, 128]) torch.float32\n",
      "seg1\n",
      "(128, 128, 128)\n",
      "Visualizing img with shape and type: torch.Size([43, 1, 128, 128]) torch.float32\n",
      "seg2\n",
      "(128, 128, 128)\n",
      "Visualizing img with shape and type: torch.Size([43, 1, 128, 128]) torch.float32\n",
      "warped_moving\n",
      "(128, 128, 128)\n",
      "Visualizing img with shape and type: torch.Size([43, 1, 128, 128]) torch.float32\n",
      "warped_seg_moving\n"
     ]
    }
   ],
   "source": [
    "dir_name = 'normal'\n",
    "(pa('images')/dir_name).mkdir(exist_ok=True)\n",
    "# include img1,2 seg1,2 warped_moving\n",
    "keys = ['img1', 'img2', 'seg1', 'seg2', 'warped_moving']\n",
    "\n",
    "k = 'warped_seg_moving'\n",
    "p = np.maximum((dct[k][...,0,1]>0.5)*2,(dct[k][...,0,0]>0.5))\n",
    "\n",
    "seg_pairs = list(zip(*[dct[k][...,0] for k in keys], p))\n",
    "keys.append(k)\n",
    "\n",
    "vis_id = -2\n",
    "\n",
    "def vis_basic():\n",
    "    for s in list(seg_pairs)[vis_id:vis_id+1]:\n",
    "        for i in range(len(s)):\n",
    "            print(s[i].shape)\n",
    "            # print(np.unique(s[i]))\n",
    "            visulize_3d(s[i], inter_dst=3, save_name=f'images/{dir_name}/{keys[i]}.jpg')\n",
    "            print(keys[i])\n",
    "        break\n",
    "\n",
    "vis_basic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the slice with most tumorus\n",
    "def get_most_tumorus_slice(seg):\n",
    "    assert seg.ndim==3\n",
    "    return np.argmax(seg.sum(axis=(2,1)))\n",
    "# get bounding box on img\n",
    "def get_bbox(seg):\n",
    "    assert seg.ndim==3\n",
    "    nz = seg.nonzero()\n",
    "    lft = nz[0].min(), nz[1].min(), nz[2].min()\n",
    "    rgt = nz[0].max(), nz[1].max(), nz[2].max()\n",
    "    return np.concatenate([lft, rgt])\n",
    "\n",
    "dct_keys = dict(zip(keys, zip(*seg_pairs)))\n",
    "\n",
    "def visualize_bbox_img(dct, keys=['seg1', 'img1']):\n",
    "    sli_num = get_most_tumorus_slice(dct[f'{keys[0]}'][vis_id]>1.5)\n",
    "    print(sli_num)\n",
    "    seg = dct[f'{keys[0]}'][vis_id][sli_num][None]\n",
    "    img = dct[keys[1]][vis_id][sli_num][None]\n",
    "    bbox = get_bbox(seg>1.5)\n",
    "    print(bbox)\n",
    "    img = draw_3d_box_on_vol(img[None], bbox[None])\n",
    "    save_image(img, f'images/{dir_name}/{keys[1]}.jpg')\n",
    "    # save seg\n",
    "    save_image((torch.tensor(seg)>1.5).float(), f'images/{dir_name}/{keys[0]}.jpg')\n",
    "\n",
    "# visualize_bbox_img(dct_keys, keys=['seg1', 'img1'])\n",
    "# visualize_bbox_img(dct_keys, keys=['seg2', 'img2'])\n",
    "# visualize_bbox_img(dct_keys, keys=['warped_seg_moving', 'warped_moving'])\n",
    "\n",
    "# union of seg\n",
    "seg1 = dct_keys['seg1'][vis_id]\n",
    "seg2 = (dct_keys['seg2'][vis_id]==2).astype(np.int)*2\n",
    "seg = np.maximum(seg1[103], seg2[89])\n",
    "w_img = dct_keys['warped_moving'][vis_id][98]\n",
    "w_img[seg==2]=0\n",
    "# save w_img\n",
    "save_image(torch.tensor(w_img)/255, f'images/{dir_name}/w_img.jpg')\n",
    "# save_image((torch.tensor(seg)).float()/2, f'images/{dir_name}/seg.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D grid + color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "# visualize each flow in plt subplot\n",
    "def plot_flow(flows, width, inter_dst):\n",
    "    le = len(flows[::inter_dst])\n",
    "    r = (le+width-1)//width\n",
    "    fig, axes = plt.subplots(r, width, figsize=(width*7, r*5))\n",
    "    print(r)\n",
    "    x, y, z = np.meshgrid(np.arange(128), np.arange(128), np.arange(128), indexing='ij')\n",
    "    u, v, w = np.transpose(flows, (-1, 0, 1, 2))\n",
    "    fx, fy, fz = u, y+v, z+w\n",
    "    fff = np.stack((fx, fy, fz), axis=1)[::inter_dst]\n",
    "    for flow, ax in zip(fff, axes.flat):\n",
    "        cp = plot_single_flow(flow, fig, ax)\n",
    "        fig.colorbar(cp, ax=ax)\n",
    "    fig.tight_layout(pad=0)\n",
    "    \n",
    "\n",
    "def plot_single_flow(flow, fig, ax):\n",
    "    fx, fy, fz = flow\n",
    "    plot_grid(fz, fy, ax, colors='black', alpha=0.3)\n",
    "    cp = ax.contourf(fz, fy, fx, cmap='bwr', alpha=0.3)\n",
    "    ax.axis('off')\n",
    "    return cp\n",
    "\n",
    "def plot_grid(x,y, ax=None, **kwargs):\n",
    "    ax = ax or plt.gca()\n",
    "    segs1 = np.stack((x,y), axis=2)\n",
    "    segs2 = segs1.transpose(1,0,2)\n",
    "    ax.add_collection(LineCollection(segs1, **kwargs))\n",
    "    ax.add_collection(LineCollection(segs2, **kwargs))\n",
    "    ax.autoscale()\n",
    "    return ax\n",
    "\n",
    "flow = dct['real_flow'][1]\n",
    "plot_flow(flow, 5, 3)\n",
    "plt.savefig('plt.png')\n",
    "# plt.show()\n",
    "# fig.canvas.draw()\n",
    "\n",
    "# Now we can save it to a numpy array.\n",
    "# data = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "# data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unused"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vector field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(x, sk):\n",
    "    return x[::sk, ::sk, ::sk]\n",
    "x,y,z = np.meshgrid(np.arange(128), np.arange(128), np.arange(128), indexing='ij')\n",
    "u, v, w = np.transpose(flow, (-1, 0, 1, 2))\n",
    "\n",
    "ax = plt.figure(figsize=(10,10)).add_subplot(projection='3d')\n",
    "\n",
    "nu,nv,nw = sample(u+x,24), sample(v+y,24), sample(w+z,24)\n",
    "# ax.scatter(sample(x, 12), sample(y, 12), sample(z,12), s=1, c='r')\n",
    "# ax.scatter(nu, nv, nw, s=10, c='r')\n",
    "for i in range(nu.shape[0]):\n",
    "    # ax.plot_wireframe(nu[i], nv[i], nw[i], rstride=1, cstride=1, linewidth=1)\n",
    "    # ax.plot_wireframe(nu[i], nv[i], nw[i], rstride=1, cstride=1, linewidth=1)\n",
    "    ax.plot_surface(nu[i], nv[i], nw[i], rstride=1, cstride=1, cmap=plt.get_cmap('gist_earth'))\n",
    "    break\n",
    "ax.view_init(0, 0)\n",
    "\n",
    "# ax.quiver(sample(x, 12), sample(y, 12), sample(z,12), sample(u,12), sample(v,12), sample(w,12), length=1, normalize=True, linewidth=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wireframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "# Grab some test data.\n",
    "X, Y, Z = axes3d.get_test_data(0.05)\n",
    "\n",
    "# Plot a basic wireframe.\n",
    "# ax.plot_wireframe(X, Y, Z, rstride=10, cstride=10)\n",
    "# ax.plot_wireframe(X+5, Y, Z+10, rstride=10, cstride=10)\n",
    "ax.quiver(X,Y,Z, length=0.1, normalize=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_area(seg):\n",
    "    return np.sum(np.sum(seg>1.5, axis=1), axis=1)\n",
    "plt.plot(cal_area(dct['seg1'][0,...,1]))\n",
    "# plt.plot(cal_area(p[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_util.liver import Dataset\n",
    "ds = Dataset('/home/hynx/regis/Recursive-Cascaded-Networks/datasets/liver_mini.json', batch_size=1)\n",
    "gen = ds.generator('lits')\n",
    "a = next(gen)\n",
    "a['id1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['lits/108',\n",
       "  'lits/113',\n",
       "  'lits/129',\n",
       "  'lits/68',\n",
       "  'lits/99',\n",
       "  'lits/4',\n",
       "  'lits/59',\n",
       "  'lits/100',\n",
       "  'lits/10',\n",
       "  'lits/127',\n",
       "  'lits/18',\n",
       "  'lits/62',\n",
       "  'lits/23',\n",
       "  'lits/98',\n",
       "  'lits/88',\n",
       "  'lits/25',\n",
       "  'lits/103',\n",
       "  'lits/45',\n",
       "  'lits/34',\n",
       "  'lits/41',\n",
       "  'lits/31',\n",
       "  'lits/11',\n",
       "  'lits/64',\n",
       "  'lits/110',\n",
       "  'lits/109',\n",
       "  'lits/38',\n",
       "  'lits/117',\n",
       "  'lits/119',\n",
       "  'lits/67',\n",
       "  'lits/1',\n",
       "  'lits/85',\n",
       "  'lits/43',\n",
       "  'lits/90',\n",
       "  'lits/55',\n",
       "  'lits/91',\n",
       "  'lits/125',\n",
       "  'lits/13',\n",
       "  'lits/8',\n",
       "  'lits/72',\n",
       "  'lits/2',\n",
       "  'lits/15',\n",
       "  'lits/37',\n",
       "  'lits/26',\n",
       "  'lits/104',\n",
       "  'lits/80',\n",
       "  'lits/126',\n",
       "  'lits/21',\n",
       "  'lits/94',\n",
       "  'lits/77',\n",
       "  'lits/19',\n",
       "  'lits/35',\n",
       "  'lits/63',\n",
       "  'lits/16',\n",
       "  'lits/66',\n",
       "  'lits/50',\n",
       "  'lits/17',\n",
       "  'lits/54',\n",
       "  'lits/6',\n",
       "  'lits/96',\n",
       "  'lits/95',\n",
       "  'lits/112',\n",
       "  'lits/82',\n",
       "  'lits/86',\n",
       "  'lits/120',\n",
       "  'lits/28',\n",
       "  'lits/114',\n",
       "  'lits/0',\n",
       "  'lits/87',\n",
       "  'lits/105',\n",
       "  'lits/7',\n",
       "  'lits/130',\n",
       "  'lits/57',\n",
       "  'lits/124',\n",
       "  'lits/29',\n",
       "  'lits/14',\n",
       "  'lits/70',\n",
       "  'lits/81',\n",
       "  'lits/32',\n",
       "  'lits/116',\n",
       "  'lits/76',\n",
       "  'lits/111',\n",
       "  'lits/93',\n",
       "  'lits/118',\n",
       "  'lits/106',\n",
       "  'lits/97',\n",
       "  'lits/53',\n",
       "  'lits/33',\n",
       "  'lits/71',\n",
       "  'lits/75',\n",
       "  'lits/128',\n",
       "  'lits/40',\n",
       "  'lits/47',\n",
       "  'lits/83',\n",
       "  'lits/39',\n",
       "  'lits/20',\n",
       "  'lits/61',\n",
       "  'lits/3',\n",
       "  'lits/89',\n",
       "  'lits/123',\n",
       "  'lits/24'],\n",
       " ['lits/84',\n",
       "  'lits/115',\n",
       "  'lits/92',\n",
       "  'lits/51',\n",
       "  'lits/36',\n",
       "  'lits/101',\n",
       "  'lits/74',\n",
       "  'lits/78',\n",
       "  'lits/27',\n",
       "  'lits/69',\n",
       "  'lits/12',\n",
       "  'lits/30',\n",
       "  'lits/52',\n",
       "  'lits/56',\n",
       "  'lits/44',\n",
       "  'lits/60',\n",
       "  'lits/48',\n",
       "  'lits/9',\n",
       "  'lits/121',\n",
       "  'lits/122',\n",
       "  'lits/5',\n",
       "  'lits/102',\n",
       "  'lits/107',\n",
       "  'lits/49',\n",
       "  'lits/79',\n",
       "  'lits/73',\n",
       "  'lits/58',\n",
       "  'lits/22',\n",
       "  'lits/65',\n",
       "  'lits/42',\n",
       "  'lits/46'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split train and val\n",
    "lst = [f\"lits/{i}\" for i in range(131)]\n",
    "lst = np.random.permutation(lst)\n",
    "lst[:100].tolist(), lst[100:].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '10', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '11', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '12', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '13', '130', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '7', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '8', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '9', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99']\n",
      "131\n",
      "['point' 'segmentation' 'volume']\n",
      "uint8\n",
      "Visualizing img with shape and type: torch.Size([26, 1, 128, 128]) torch.float32\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255]\n",
      "Visualizing img with shape and type: torch.Size([26, 1, 128, 128]) torch.float32\n",
      "[0 1]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# read hd5f file and get the data\n",
    "import h5py\n",
    "import numpy as np\n",
    "from adet.utils.visualize_niigz import *\n",
    "# path = '/home/hynx/regis/Recursive-Cascaded-Networks/datasets/sliver_val.h5'\n",
    "# path = '/home/hynx/regis/Recursive-Cascaded-Networks/datasets/lits_uint8.h5'\n",
    "path = '/home/hynx/regis/Recursive-Cascaded-Networks/datasets/lits_bkp.h5'\n",
    "# path = '/home/hynx/regis/Recursive-Cascaded-Networks/datasets/youyi_liver.h5'   \n",
    "# path = '/home/hynx/regis/Recursive-Cascaded-Networks/datasets/msd_dataset.h5'\n",
    "# path = '/home/hynx/regis/Recursive-Cascaded-Networks/datasets/lspig_val.h5'\n",
    "# path = '/home/hynx/regis/Recursive-Cascaded-Networks/datasets/lpba_val.h5'\n",
    "f = h5py.File(path, 'r')\n",
    "# print(len(f))\n",
    "ks = list(f.keys())\n",
    "print(ks)\n",
    "print(len(ks))\n",
    "# for k in ks:\n",
    "#     print(k, len(f[k].keys()))\n",
    "print(np.array(f[ks[0]]))\n",
    "\n",
    "def cal_data():\n",
    "    for k in f:\n",
    "        data = f[k]['volume']\n",
    "        data = np.array(data)\n",
    "        print(data.dtype)\n",
    "        visulize_3d(data, save_name='img1.png')\n",
    "        print(np.unique(data))\n",
    "        break\n",
    "def cal_seg():\n",
    "    for k in f:\n",
    "        seg = f[k]['segmentation']\n",
    "        seg = np.array(seg)\n",
    "        visulize_3d(seg, save_name='seg1.png')\n",
    "        print(np.unique(seg))\n",
    "        if (seg>1.5).sum()==0:\n",
    "            print(k)\n",
    "        break\n",
    "cal_data()\n",
    "cal_seg()\n",
    "\n",
    "def visualize_every_sample(f, dir):\n",
    "    for k in f:\n",
    "        data = np.array(f[k]['volume'])\n",
    "        seg= np.array(f[k]['segmentation'])\n",
    "        visulize_3d(data, save_name=f'images/{dir}/{k}_img.png')\n",
    "        visulize_3d(seg, save_name=f'images/{dir}/{k}_seg.png')\n",
    "        print(k)\n",
    "dir = 'sliver'\n",
    "# makedir\n",
    "# if not os.path.exists(f'images/{dir}'):\n",
    "#     os.makedirs(f'images/{dir}')\n",
    "# visualize_every_sample(f, dir)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py, numpy as np\n",
    "path = '/home/hynx/regis/Recursive-Cascaded-Networks/datasets/lits_bkp.h5'\n",
    "f = h5py.File(path, 'r+')\n",
    "# turn label 255 to 1\n",
    "def modify_h5():\n",
    "    for k in f:\n",
    "        data = f[k]['segmentation']\n",
    "        data = np.array(data)\n",
    "        # normalize data to 0-255\n",
    "        # data = (data - data.min()) / (data.max() - data.min()) * 255\n",
    "        # binarize seg\n",
    "        data = data>255/2\n",
    "        data = data.astype(np.uint8)\n",
    "        f[k]['segmentation'][...] = data\n",
    "# modify_h5()     \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# random.shuffle(ks)\n",
    "# with open('/home/hynx/regis/Recursive-Cascaded-Networks/datasets/lits.txt', 'w') as f:\n",
    "#     for k in ks:\n",
    "#         f.write(k + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('nnFormer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45b791b08232f65da906b1dd6ccc8b0664ad17ad103836e42c8cd9dd7c999693"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
